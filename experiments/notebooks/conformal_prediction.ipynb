{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformal Prediction in APDTFlow v0.2.0\n",
    "\n",
    "## Rigorous Uncertainty Quantification! ðŸ“Š\n",
    "\n",
    "This notebook demonstrates **conformal prediction** for calibrated prediction intervals with **finite-sample coverage guarantees**.\n",
    "\n",
    "### What is Conformal Prediction?\n",
    "\n",
    "A distribution-free method that provides:\n",
    "- **Guaranteed coverage** (e.g., 95% of true values fall in the interval)\n",
    "- **No distribution assumptions** required\n",
    "- **Finite-sample guarantees** (not just asymptotic!)\n",
    "- **Adaptive to non-stationary data**\n",
    "\n",
    "### Why It Matters\n",
    "\n",
    "- Traditional probabilistic forecasts can be **miscalibrated**\n",
    "- Conformal prediction gives **GUARANTEED** coverage\n",
    "- Critical for **decision-making** in business/healthcare/finance\n",
    "- **Hottest topic** in 2025 time series research!\n",
    "\n",
    "### Research References\n",
    "\n",
    "- arXiv:2509.02844 - Conformal Prediction for Time Series\n",
    "- arXiv:2503.21251 - Dual-Splitting for Multi-Step\n",
    "- ICLR 2025 - Kernel-based Optimally Weighted CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from apdtflow import APDTFlowForecaster\n",
    "from apdtflow.conformal import (\n",
    "    SplitConformalPredictor,\n",
    "    AdaptiveConformalPredictor,\n",
    "    plot_conformal_intervals\n",
    ")\n",
    "\n",
    "print(\"âœ“ APDTFlow v0.2.0 Conformal Prediction loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic Time Series\n",
    "\n",
    "Create data with trend + seasonality + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate 500 days of data\n",
    "dates = pd.date_range(start='2023-01-01', periods=500, freq='D')\n",
    "t = np.arange(len(dates))\n",
    "\n",
    "# Components\n",
    "trend = 0.05 * t\n",
    "seasonality = 10 * np.sin(2 * np.pi * t / 30)  # 30-day cycle\n",
    "noise = np.random.normal(0, 2, len(t))\n",
    "\n",
    "values = 100 + trend + seasonality + noise\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'value': values\n",
    "})\n",
    "\n",
    "print(f\"Dataset: {len(df)} days\")\n",
    "print(f\"Components: Trend + 30-day seasonality + Gaussian noise\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(df['date'], df['value'])\n",
    "plt.title('Synthetic Time Series', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split Conformal Prediction\n",
    "\n",
    "The simplest and most reliable conformal method.\n",
    "\n",
    "**How it works:**\n",
    "1. Split data: Train (60%) / Calibration (20%) / Test (20%)\n",
    "2. Train model on training set\n",
    "3. Compute nonconformity scores on calibration set\n",
    "4. Use quantile of scores to construct prediction intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "n = len(df)\n",
    "train_end = int(0.6 * n)\n",
    "cal_end = int(0.8 * n)\n",
    "\n",
    "train_data = df.iloc[:train_end]\n",
    "cal_data = df.iloc[train_end:cal_end]\n",
    "test_data = df.iloc[cal_end:]\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Training:    {len(train_data)} samples\")\n",
    "print(f\"  Calibration: {len(cal_data)} samples\")\n",
    "print(f\"  Test:        {len(test_data)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train base forecaster\n",
    "model = APDTFlowForecaster(\n",
    "    forecast_horizon=1,\n",
    "    history_length=30,\n",
    "    num_epochs=30,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model.fit(train_data, target_col='value', date_col='date')\n",
    "print(\"âœ“ Base model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction function for conformal predictor\n",
    "def predict_fn(X):\n",
    "    \"\"\"Wrapper to predict on arbitrary inputs.\"\"\"\n",
    "    # X is a 2D array (n_samples, history_length)\n",
    "    preds = []\n",
    "    for i in range(len(X)):\n",
    "        # Temporarily set last sequence\n",
    "        old_seq = model.last_sequence_\n",
    "        model.last_sequence_ = X[i]\n",
    "        pred = model.predict()\n",
    "        preds.append(pred[0])\n",
    "        model.last_sequence_ = old_seq\n",
    "    return np.array(preds)\n",
    "\n",
    "# Prepare calibration data\n",
    "cal_values = cal_data['value'].values\n",
    "X_cal = np.array([cal_values[i-30:i] for i in range(30, len(cal_values))])\n",
    "y_cal = cal_values[30:]\n",
    "\n",
    "print(f\"Calibration set: {len(X_cal)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and calibrate conformal predictor\n",
    "conformal = SplitConformalPredictor(\n",
    "    predict_fn=predict_fn,\n",
    "    alpha=0.05  # 95% coverage\n",
    ")\n",
    "\n",
    "conformal.calibrate(X_cal, y_cal)\n",
    "print(\"\\nâœ“ Conformal predictor calibrated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Coverage on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "test_values = test_data['value'].values\n",
    "X_test = np.array([test_values[i-30:i] for i in range(30, len(test_values))])\n",
    "y_test = test_values[30:]\n",
    "\n",
    "# Get conformal predictions\n",
    "lower, pred, upper = conformal.predict(X_test)\n",
    "\n",
    "# Calculate empirical coverage\n",
    "covered = (y_test >= lower) & (y_test <= upper)\n",
    "empirical_coverage = np.mean(covered)\n",
    "\n",
    "print(f\"Empirical Coverage: {empirical_coverage:.1%}\")\n",
    "print(f\"Target Coverage:    {1-conformal.alpha:.1%}\")\n",
    "print(f\"\\nAverage Interval Width: {np.mean(upper - lower):.2f}\")\n",
    "print(f\"Quantile Value: {conformal.quantile:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize conformal intervals\n",
    "plot_conformal_intervals(\n",
    "    y_true=y_test[:50],\n",
    "    y_pred=pred[:50],\n",
    "    lower=lower[:50],\n",
    "    upper=upper[:50],\n",
    "    title=f\"Split Conformal Prediction (Coverage: {empirical_coverage:.1%})\",\n",
    "    figsize=(14, 6)\n",
    ")\n",
    "\n",
    "print(f\"Notice: ~{empirical_coverage:.0%} of true values fall within the intervals!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Adaptive Conformal Prediction\n",
    "\n",
    "For **non-stationary** data where the distribution changes over time.\n",
    "\n",
    "**How it works:**\n",
    "- Starts with split conformal calibration\n",
    "- Adapts the interval width online based on recent errors\n",
    "- Maintains coverage even when data distribution shifts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create non-stationary data (increasing variance over time)\n",
    "np.random.seed(42)\n",
    "dates_ns = pd.date_range(start='2023-01-01', periods=500, freq='D')\n",
    "t_ns = np.arange(len(dates_ns))\n",
    "\n",
    "# Variance increases over time!\n",
    "trend_ns = 0.05 * t_ns\n",
    "seasonality_ns = 10 * np.sin(2 * np.pi * t_ns / 30)\n",
    "noise_std = 2 + 0.01 * t_ns  # Increasing noise!\n",
    "noise_ns = np.random.normal(0, noise_std)\n",
    "\n",
    "values_ns = 100 + trend_ns + seasonality_ns + noise_ns\n",
    "\n",
    "df_ns = pd.DataFrame({\n",
    "    'date': dates_ns,\n",
    "    'value': values_ns\n",
    "})\n",
    "\n",
    "print(\"Non-stationary dataset created\")\n",
    "print(\"Variance increases over time!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize increasing variance\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(df_ns['date'], df_ns['value'])\n",
    "plt.title('Non-Stationary Time Series (Increasing Variance)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how the fluctuations get larger over time!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_ns = df_ns.iloc[:300]\n",
    "cal_ns = df_ns.iloc[300:400]\n",
    "test_ns = df_ns.iloc[400:]\n",
    "\n",
    "# Train model\n",
    "model_ns = APDTFlowForecaster(\n",
    "    forecast_horizon=1,\n",
    "    history_length=30,\n",
    "    num_epochs=30,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model_ns.fit(train_ns, target_col='value', date_col='date')\n",
    "print(\"âœ“ Model trained on non-stationary data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction function\n",
    "def predict_fn_ns(X):\n",
    "    preds = []\n",
    "    for i in range(len(X)):\n",
    "        old_seq = model_ns.last_sequence_\n",
    "        model_ns.last_sequence_ = X[i]\n",
    "        pred = model_ns.predict()\n",
    "        preds.append(pred[0])\n",
    "        model_ns.last_sequence_ = old_seq\n",
    "    return np.array(preds)\n",
    "\n",
    "# Prepare calibration data\n",
    "cal_values_ns = cal_ns['value'].values\n",
    "X_cal_ns = np.array([cal_values_ns[i-30:i] for i in range(30, len(cal_values_ns))])\n",
    "y_cal_ns = cal_values_ns[30:]\n",
    "\n",
    "print(f\"Calibration: {len(X_cal_ns)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ADAPTIVE conformal predictor\n",
    "adaptive_conformal = AdaptiveConformalPredictor(\n",
    "    predict_fn=predict_fn_ns,\n",
    "    alpha=0.05,\n",
    "    gamma=0.05  # Learning rate for adaptation\n",
    ")\n",
    "\n",
    "adaptive_conformal.calibrate(X_cal_ns, y_cal_ns)\n",
    "print(\"\\nâœ“ Adaptive conformal predictor calibrated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online prediction with adaptation\n",
    "test_values_ns = test_ns['value'].values\n",
    "predictions_adaptive = []\n",
    "lower_adaptive = []\n",
    "upper_adaptive = []\n",
    "\n",
    "for i in range(30, len(test_values_ns)):\n",
    "    X_t = test_values_ns[i-30:i].reshape(1, -1)\n",
    "    y_t = test_values_ns[i]\n",
    "    \n",
    "    # Predict and update\n",
    "    lower_t, pred_t, upper_t = adaptive_conformal.predict_and_update(X_t, y_t.reshape(1))\n",
    "    \n",
    "    predictions_adaptive.append(pred_t[0])\n",
    "    lower_adaptive.append(lower_t[0])\n",
    "    upper_adaptive.append(upper_t[0])\n",
    "\n",
    "y_test_ns = test_values_ns[30:]\n",
    "predictions_adaptive = np.array(predictions_adaptive)\n",
    "lower_adaptive = np.array(lower_adaptive)\n",
    "upper_adaptive = np.array(upper_adaptive)\n",
    "\n",
    "# Calculate coverage\n",
    "covered_adaptive = (y_test_ns >= lower_adaptive) & (y_test_ns <= upper_adaptive)\n",
    "coverage_adaptive = np.mean(covered_adaptive)\n",
    "\n",
    "print(f\"Adaptive Conformal Coverage: {coverage_adaptive:.1%}\")\n",
    "print(f\"Target Coverage:             {1-adaptive_conformal.alpha:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize adaptive intervals\n",
    "plot_conformal_intervals(\n",
    "    y_true=y_test_ns,\n",
    "    y_pred=predictions_adaptive,\n",
    "    lower=lower_adaptive,\n",
    "    upper=upper_adaptive,\n",
    "    title=f\"Adaptive Conformal Prediction (Coverage: {coverage_adaptive:.1%})\",\n",
    "    figsize=(14, 6)\n",
    ")\n",
    "\n",
    "print(\"Notice how the interval width adapts to increasing variance!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get adaptation statistics\n",
    "stats = adaptive_conformal.get_adaptation_stats()\n",
    "\n",
    "print(\"\\nAdaptation Statistics:\")\n",
    "print(f\"  Updates performed:    {stats['num_updates']}\")\n",
    "print(f\"  Initial quantile:     {stats['initial_quantile']:.2f}\")\n",
    "print(f\"  Current quantile:     {stats['current_quantile']:.2f}\")\n",
    "print(f\"  Quantile change:      {stats['quantile_change']:.2f}\")\n",
    "print(f\"  Recent coverage:      {stats['recent_coverage']:.1%}\")\n",
    "print(f\"  Target coverage:      {stats['target_coverage']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Comparison - Split vs Adaptive\n",
    "\n",
    "Let's compare both methods on the non-stationary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also run split conformal on non-stationary data\n",
    "split_conformal_ns = SplitConformalPredictor(\n",
    "    predict_fn=predict_fn_ns,\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "split_conformal_ns.calibrate(X_cal_ns, y_cal_ns)\n",
    "\n",
    "# Prepare test data\n",
    "X_test_ns = np.array([test_values_ns[i-30:i] for i in range(30, len(test_values_ns))])\n",
    "\n",
    "# Predict\n",
    "lower_split, pred_split, upper_split = split_conformal_ns.predict(X_test_ns)\n",
    "\n",
    "# Coverage\n",
    "covered_split = (y_test_ns >= lower_split) & (y_test_ns <= upper_split)\n",
    "coverage_split = np.mean(covered_split)\n",
    "\n",
    "print(f\"Split Conformal Coverage:    {coverage_split:.1%}\")\n",
    "print(f\"Adaptive Conformal Coverage: {coverage_adaptive:.1%}\")\n",
    "print(f\"Target Coverage:             95.0%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare interval widths over time\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "x = np.arange(len(y_test_ns))\n",
    "\n",
    "# Split conformal\n",
    "ax1.plot(x, y_test_ns, 'ko-', label='Actual', alpha=0.6, markersize=4)\n",
    "ax1.fill_between(x, lower_split, upper_split, alpha=0.3, color='blue', label='Split Conformal')\n",
    "ax1.set_title(f'Split Conformal (Coverage: {coverage_split:.1%})', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Value')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Adaptive conformal\n",
    "ax2.plot(x, y_test_ns, 'ko-', label='Actual', alpha=0.6, markersize=4)\n",
    "ax2.fill_between(x, lower_adaptive, upper_adaptive, alpha=0.3, color='red', label='Adaptive Conformal')\n",
    "ax2.set_title(f'Adaptive Conformal (Coverage: {coverage_adaptive:.1%})', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Time Step')\n",
    "ax2.set_ylabel('Value')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Observation:\")\n",
    "print(\"  Split: Fixed interval width (may undercover later)\")\n",
    "print(\"  Adaptive: Intervals widen as variance increases (maintains coverage!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Integration with APDTFlowForecaster\n",
    "\n",
    "Use conformal prediction directly in the high-level API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with conformal prediction enabled\n",
    "model_conformal = APDTFlowForecaster(\n",
    "    forecast_horizon=7,\n",
    "    history_length=30,\n",
    "    num_epochs=30,\n",
    "    use_conformal=True,\n",
    "    conformal_method='split',  # or 'adaptive'\n",
    "    calibration_split=0.2,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Train (automatically splits for calibration)\n",
    "model_conformal.fit(train_data, target_col='value', date_col='date')\n",
    "\n",
    "print(\"âœ“ Model with conformal prediction trained\")\n",
    "print(\"  20% of training data used for calibration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get conformal prediction intervals\n",
    "lower_api, pred_api, upper_api = model_conformal.predict(\n",
    "    alpha=0.05,\n",
    "    return_intervals='conformal'\n",
    ")\n",
    "\n",
    "print(f\"Predictions with 95% conformal intervals:\")\n",
    "print(f\"  Lower: {lower_api}\")\n",
    "print(f\"  Pred:  {pred_api}\")\n",
    "print(f\"  Upper: {upper_api}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### 1. Why Conformal Prediction?\n",
    "\n",
    "**Traditional Uncertainty:**\n",
    "- Based on model assumptions (e.g., Gaussian)\n",
    "- Can be miscalibrated\n",
    "- No guarantees\n",
    "\n",
    "**Conformal Prediction:**\n",
    "- Distribution-free (no assumptions!)\n",
    "- Finite-sample coverage guarantees\n",
    "- Theoretically rigorous\n",
    "\n",
    "### 2. Split vs Adaptive\n",
    "\n",
    "**Split Conformal:**\n",
    "- Simple and reliable\n",
    "- Best for stationary data\n",
    "- Fixed interval width\n",
    "\n",
    "**Adaptive Conformal:**\n",
    "- For non-stationary data\n",
    "- Intervals adapt to changing variance\n",
    "- Maintains coverage under distribution shift!\n",
    "\n",
    "### 3. When to Use\n",
    "\n",
    "Use conformal prediction when:\n",
    "- **Decision-making** requires guaranteed coverage\n",
    "- **Risk management** (finance, healthcare)\n",
    "- **Safety-critical** applications\n",
    "- **Regulatory requirements** for uncertainty quantification\n",
    "\n",
    "### 4. API Usage\n",
    "\n",
    "```python\n",
    "# Method 1: Direct usage\n",
    "from apdtflow.conformal import SplitConformalPredictor\n",
    "\n",
    "conformal = SplitConformalPredictor(predict_fn, alpha=0.05)\n",
    "conformal.calibrate(X_cal, y_cal)\n",
    "lower, pred, upper = conformal.predict(X_test)\n",
    "\n",
    "# Method 2: Integrated with forecaster\n",
    "model = APDTFlowForecaster(\n",
    "    use_conformal=True,\n",
    "    conformal_method='split'\n",
    ")\n",
    "\n",
    "model.fit(df)\n",
    "lower, pred, upper = model.predict(return_intervals='conformal')\n",
    "```\n",
    "\n",
    "### 5. Research References\n",
    "\n",
    "- **arXiv:2509.02844**: Conformal Prediction for Time Series with Change Points\n",
    "- **ICLR 2025**: Kernel-based Optimally Weighted Conformal Prediction\n",
    "- **arXiv:2503.21251**: Dual-Splitting for Multi-Step Forecasting\n",
    "- **NeurIPS 2021**: Adaptive Conformal Inference Under Distribution Shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Try with your own data!\n",
    "2. Experiment with different alpha levels (90%, 95%, 99%)\n",
    "3. Combine with exogenous variables (see `exogenous_variables.ipynb`)\n",
    "4. Compare coverage across different models\n",
    "\n",
    "ðŸ“š **Documentation**: https://github.com/yotambraun/APDTFlow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
